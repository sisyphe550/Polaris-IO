services:
  #jaeger链路追踪 — Jaeger for tracing
  jaeger:
    image: jaegertracing/all-in-one:1.63.0
    container_name: io-jaeger
    restart: always
    ports:
      # A. 数据接收端口
      - "6831:6831/udp" # Jaeger Thrift Compact (UDP) : Jaeger Agent 默认接收数据的端口。
      - "6832:6832/udp" # Jaeger Thrift Binary (UDP) : 一种二进制格式，通常用于 Node.js 等其他语言的客户端。
      - "14268:14268" # HTTP : 允许客户端直接通过 HTTP POST 请求发送 Span 数据。
      # B. 兼容性与管理端口
      - "5775:5775/udp" # 兼容旧版的 Zipkin Thrift 协议。
      - "9411:9411" # 兼容 Zipkin V1/V2 的 HTTP 接口。
      - "5778:5778" # 配置采样策略（Sampling Strategies）。
      # C. 用户界面端口
      - "16686:16686" # Web UI
    environment:
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://io-elasticsearch:9200
      - LOG_LEVEL=debug
    depends_on:
      - elasticsearch
    networks:
      - polaris-net

  #prometheus监控 — Prometheus for monitoring
  prometheus:
    image: prom/prometheus:v2.39.1
    container_name: io-prometheus
    volumes:
      - ./deploy/prometheus/server/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./data/prometheus/data:/prometheus
    command: 
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    restart: always
    user: root
    ports:
      - "9090:9090"
    networks:
      - polaris-net

  #查看prometheus监控数据 - Grafana to view Prometheus monitoring data
  grafana:
    image: grafana/grafana:8.0.6
    container_name: io-grafana
    hostname: grafana
    user: root
    environment:
      TZ: Asia/Shanghai
    restart: always
    volumes:
      - ./data/grafana/data:/var/lib/grafana
    ports:
      - "3001:3000"
    networks:
      - polaris-net

  elasticsearch:
    container_name: io-elasticsearch
    image: elasticsearch:8.12.2
    restart: unless-stopped
    environment:
      - "ES_JAVA_OPTS=-Xms1024m -Xmx1024m"
      - "TZ=Asia/Shanghai"
      - "discovery.type=single-node"
      - "xpack.security.enabled=false"
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - ./data/es/data:/usr/share/elasticsearch/data
      - ./data/es/plugins:/usr/share/elasticsearch/plugins
    networks:
      - polaris-net

  kibana:
    container_name: io-kibana
    image: kibana:8.12.2
    restart: unless-stopped
    environment:
      - "TZ=Asia/Shanghai"
      - "I18N_LOCALE=zh-CH"
      - "ELASTICSEARCH_HOSTS=http://io-elasticsearch:9200"
      - "XPACK_SECURITY_ENABLED=false"
    ports:
      - "5601:5601"
    networks:
      - polaris-net
    depends_on:
      - elasticsearch
  
  # 消费Kafka中filebeat收集的数据输出到es - The data output collected by FileBeat in Kafka is output to ES
  go-stash:
    image: kevinwan/go-stash:1.1.1
    container_name: io-go-stash
    environment:
      TZ: Asia/Shanghai
    restart: always
    volumes:
      - ./deploy/go-stash/etc:/app/etc
    networks:
      - polaris-net
    depends_on:
      - elasticsearch
      - kafka

  # 收集业务数据 - Collect business data
  filebeat:
    image: elastic/filebeat:8.12.2
    container_name: io-filebeat
    environment:
      TZ: Asia/Shanghai
    user: root
    restart: always
    entrypoint: "filebeat -e -strict.perms=false"
    volumes:
      - ./deploy/filebeat/conf/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - /var/lib/docker/containers:/var/lib/docker/containers
    networks:
      - polaris-net
    depends_on:
      - kafka
  
  # 消息队列 - Message queue
  kafka:
    image: apache/kafka:3.9.0
    container_name: io-kafka
    ports:
      - 9092:9092 # 容器内部之间使用的监听端口
      - 9094:9094 # 容器外部访问监听端口
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      # 外部访问监听端口为 9092，容器内部使用不同的端口 9094
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9094,CONTROLLER://localhost:9093,PLAINTEXT_CONTAINER://kafka:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9094,PLAINTEXT_CONTAINER://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_CONTAINER:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
      - ./data/kafka/data:/var/lib/kafka/data
    networks:
      - polaris-net

  asynqmon:
    image: hibiken/asynqmon:latest
    platform: linux/amd64
    container_name: io-asynqmon
    ports:
      - 8900:8080
    command: 
      - '--redis-addr=redis:6379'
      - '--redis-password=polaris'
    restart: always
    networks:
      - polaris-net
    depends_on:
      - redis    

  # 1. 服务注册发现 (Go-zero 强依赖)
  etcd:
    # 替换为 quay.io 镜像源，避开 bitnami 的限制
    image: quay.io/coreos/etcd:v3.5.5
    container_name: io-etcd
    environment:
      TZ: Asia/Shanghai
      ETCD_NAME: wb-etcd
      ETCD_DATA_DIR: /etcd-data
      ETCD_AUTO_COMPACTION_RETENTION: "1"    # 每1小时自动压缩历史数据
      ETCD_AUTO_COMPACTION_MODE: periodic    # 周期性压缩模式
    ports:
      - "2379:2379"   # 客户端通信端口
      - "2380:2380"   # peer 通信端口 (集群扩展预留)
    command:
      - /usr/local/bin/etcd
      - --listen-client-urls=http://0.0.0.0:2379
      - --advertise-client-urls=http://etcd:2379
      - --listen-peer-urls=http://0.0.0.0:2380
      - --initial-advertise-peer-urls=http://etcd:2380
      - --initial-cluster=wb-etcd=http://etcd:2380
      - --initial-cluster-token=wb-etcd-cluster
      - --initial-cluster-state=new
      - --data-dir=/etcd-data
      - --quota-backend-bytes=8589934592     # 8GB 存储配额
      - --max-request-bytes=10485760         # 10MB 最大请求大小
      - --log-level=debug
    volumes:
      - ./data/etcd/data:/etcd-data
    restart: always
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health", "--endpoints=http://127.0.0.1:2379"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - polaris-net

  # 2. 关系型数据库
  mysql:
    image: mysql:8.0
    container_name: io-mysql
    environment:
      MYSQL_ROOT_PASSWORD: root
      # MYSQL_DATABASE: whiteboard
      TZ: Asia/Shanghai
    ports:
      - "33069:3306"
    volumes:
      - ./data/mysql:/var/lib/mysql
      # - ./sql:/docker-entrypoint-initdb.d # 自动执行初始化SQL
    command: 
      --default-authentication-plugin=mysql_native_password
      --character-set-server=utf8mb4
      --collation-server=utf8mb4_general_ci
      --explicit_defaults_for_timestamp=true
      --lower_case_table_names=1
    privileged: true
    restart: always
    networks:
      - polaris-net

  # 3. 缓存与消息
  redis:
    image: redis:6.2.5
    container_name: io-redis
    ports:
      - "36379:6379"
    environment:
      TZ: Asia/Shanghai
    volumes:
      - ./data/redis/data:/data:rw
    command: "redis-server --requirepass polaris --appendonly yes"
    privileged: true
    restart: always
    networks:
      - polaris-net

  # 4. 对象存储 (RustFS - Garage)
  garage:
    image: dxflrs/garage:v2.1.0
    container_name: io-storage
    environment:
      TZ: Asia/Shanghai
      RUST_LOG: info                           # 生产环境可改为 warn
      GARAGE_ADMIN_TOKEN: wb-admin-token-2024  # 管理 API 认证令牌
    ports:
      - "3900:3900"   # S3 API
      - "3901:3901"   # RPC (节点间通信)
      - "3902:3902"   # Admin API / Web 端点
    volumes:
      - ./data/garage/meta:/var/lib/garage/meta
      - ./data/garage/data:/var/lib/garage/data
      - ./deploy/config/garage.toml:/etc/garage.toml:ro
    restart: always
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://127.0.0.1:3903/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    networks:
      - polaris-net

  # 5. 文档数据库 (MongoDB)
  mongo:
    image: mongo:7.0
    container_name: io-mongo
    environment:
      TZ: Asia/Shanghai
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: wb-mongo-2024
      MONGO_INITDB_DATABASE: whiteboard        # 初始化时创建的数据库
    ports:
      - "27017:27017"
    volumes:
      - ./data/mongo/data:/data/db             # 数据持久化
      - ./data/mongo/configdb:/data/configdb   # 配置持久化
      # - ./deploy/sql/mongo-init.js:/docker-entrypoint-initdb.d/init.js:ro  # 可选：初始化脚本
    command:
      - --wiredTigerCacheSizeGB=1              # 限制内存占用 (开发环境1GB足够)
      - --bind_ip_all                          # 允许外部连接
      - --directoryperdb                       # 每个数据库独立目录
      - --storageEngine=wiredTiger             # 使用 WiredTiger 存储引擎
    restart: always
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')", "--quiet"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    networks:
      - polaris-net

  # MongoDB Web 管理界面 (可选)
  mongo-express:
    image: mongo-express:1.0.2
    container_name: io-mongo-express
    environment:
      TZ: Asia/Shanghai
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: wb-mongo-2024
      ME_CONFIG_MONGODB_URL: mongodb://root:wb-mongo-2024@mongo:27017/
      ME_CONFIG_BASICAUTH_USERNAME: admin      # Web 登录用户名
      ME_CONFIG_BASICAUTH_PASSWORD: admin123   # Web 登录密码
    ports:
      - "8081:8081"
    restart: always
    depends_on:
      - mongo
    networks:
      - polaris-net

networks:
  polaris-net:
    driver: bridge
    # name: whiteboard-net
    ipam:
      config:
        - subnet: 172.16.0.0/16